{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate metrics\n",
    "---\n",
    "\n",
    "In this notebook:\n",
    "\n",
    "1. We will extract the titles generated as completions from the bedrock models (claude sonnet, llama, mistral)\n",
    "\n",
    "2. Load these into a CSV file\n",
    "\n",
    "3. Generate metrics on accuracy, performance, token throughput, inference, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import yaml\n",
    "import glob\n",
    "import logging\n",
    "import pandas as pd  \n",
    "from ast import List\n",
    "from typing import Dict\n",
    "from pathlib import Path\n",
    "from json import JSONEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set a logger "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='[%(asctime)s] p%(process)s {%(filename)s:%(lineno)d} %(levelname)s - %(message)s', level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the config file: Contains model information, data directory information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load the config file\n",
    "# global constants\n",
    "CONFIG_FILE_PATH = \"config.yml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-01 16:14:06,591] p26176 {3034282685.py:5} INFO - config read from config.yml -> {\n",
      "  \"app_name\": \"genai-chapterize-meeting-transcripts\",\n",
      "  \"aws\": {\n",
      "    \"region\": \"us-east-1\"\n",
      "  },\n",
      "  \"dir\": {\n",
      "    \"data\": \"data\",\n",
      "    \"raw\": \"data/source_data\",\n",
      "    \"processed\": \"data/processed_data\",\n",
      "    \"completions\": \"data/title_completions\",\n",
      "    \"golden\": \"data/source_data/golden\",\n",
      "    \"prompts\": \"data/prompts\",\n",
      "    \"metrics\": \"data/metrics\",\n",
      "    \"processed_file\": \"processed.csv\",\n",
      "    \"chapterized_file\": \"chapterized.csv\",\n",
      "    \"metrics_file\": \"per_request_results.csv\",\n",
      "    \"summary_metrics_file\": \"summary_metrics.csv\",\n",
      "    \"model_evals_file\": \"model_eval.csv\",\n",
      "    \"file_type_to_process\": \"vtt\"\n",
      "  },\n",
      "  \"run_steps\": {\n",
      "    \"0_chapterize_data.ipynb\": true,\n",
      "    \"1_generate_chapter_titles.ipynb\": true,\n",
      "    \"2_summarize_metrics.ipynb\": true\n",
      "  },\n",
      "  \"inference_parameters\": {\n",
      "    \"temperature\": 0.1,\n",
      "    \"caching\": false\n",
      "  },\n",
      "  \"title_generation_thresholds\": {\n",
      "    \"max_chapter_length\": 20\n",
      "  },\n",
      "  \"experiments\": [\n",
      "    {\n",
      "      \"name\": \"chapterize-meeting-transcripts\",\n",
      "      \"prompt_template\": null,\n",
      "      \"model_list\": [\n",
      "        {\n",
      "          \"model\": \"mistral.mistral-7b-instruct-v0:2\",\n",
      "          \"prompt_template\": \"mistral_template.txt\",\n",
      "          \"max_context_window\": 32000,\n",
      "          \"input_tokens_pricing\": 0.00015,\n",
      "          \"output_tokens_pricing\": 0.0002\n",
      "        },\n",
      "        {\n",
      "          \"model\": \"anthropic.claude-3-haiku-20240307-v1:0\",\n",
      "          \"prompt_template\": \"anthropic_template.txt\",\n",
      "          \"max_context_window\": 200000,\n",
      "          \"input_tokens_pricing\": 0.00025,\n",
      "          \"output_tokens_pricing\": 0.00125\n",
      "        },\n",
      "        {\n",
      "          \"model\": \"anthropic.claude-3-sonnet-20240229-v1:0\",\n",
      "          \"max_context_window\": 200000,\n",
      "          \"prompt_template\": \"anthropic_template.txt\",\n",
      "          \"input_tokens_pricing\": 0.003,\n",
      "          \"output_tokens_pricing\": 0.015\n",
      "        },\n",
      "        {\n",
      "          \"model\": \"amazon.titan-text-express-v1\",\n",
      "          \"max_context_window\": 8000,\n",
      "          \"prompt_template\": \"titan_template.txt\",\n",
      "          \"input_tokens_pricing\": 0.0008,\n",
      "          \"output_tokens_pricing\": 0.0016\n",
      "        },\n",
      "        {\n",
      "          \"model\": \"meta.llama2-13b-chat-v1\",\n",
      "          \"max_context_window\": 4096,\n",
      "          \"prompt_template\": \"llama_template.txt\",\n",
      "          \"input_tokens_pricing\": 0.00075,\n",
      "          \"output_tokens_pricing\": 0.001\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"report\": {\n",
      "    \"summary_text\": \"The average inference latency for this workload with prompt tokens {avg_prompt_token_count} (p95 is {p95_prompt_token_count}) and completion tokens {avg_completion_token_count} (p95 is {p95_completion_token_count}) when using {model_id} is {avg_latency}s (p95 is {p95_latency}s) and the average cost for 10,000 requests is ${avg_cost} (p95 is ${p95_cost_per_txn}), this is based on {count} requests.\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# read the config yaml file\n",
    "fpath = CONFIG_FILE_PATH\n",
    "with open(fpath, 'r') as yaml_in:\n",
    "    config = yaml.safe_load(yaml_in)\n",
    "logger.info(f\"config read from {fpath} -> {json.dumps(config, indent=2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-01 16:14:06,610] p26176 {3931314738.py:4} INFO - there are 20 files in data/title_completions\\**\\*\\*.json\n"
     ]
    }
   ],
   "source": [
    "## Represents extracted all metric files\n",
    "fpath = os.path.join(config['dir']['completions'], \"**\", \"*\", \"*.json\")\n",
    "metric_files = glob.glob(fpath, recursive=True)\n",
    "logger.info(f\"there are {len(metric_files)} files in {fpath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate a simple CSV with metrics on title completions, chapters, and performance latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-01 16:14:06,637] p26176 {3027428405.py:8} INFO - all metrics data is read into a dataframe of shape (20, 10)\n"
     ]
    }
   ],
   "source": [
    "metrics = []\n",
    "for f in metric_files:\n",
    "    metrics.append(json.loads(Path(f).read_text()))\n",
    "df = pd.DataFrame(metrics)\n",
    "df = df.drop(columns=['exception', 'prompt'])\n",
    "df = df.sort_values(by=['file_name', 'model_id', 'chapter_id'])\n",
    "df = df.rename(columns={'completion': 'chapter_title', 'time_taken_in_seconds': 'latency_seconds'})\n",
    "logger.info(f\"all metrics data is read into a dataframe of shape {df.shape}\")\n",
    "count = df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_id\n",
       "amazon.titan-text-express-v1               4\n",
       "anthropic.claude-3-haiku-20240307-v1:0     4\n",
       "anthropic.claude-3-sonnet-20240229-v1:0    4\n",
       "meta.llama2-13b-chat-v1                    4\n",
       "mistral.mistral-7b-instruct-v0:2           4\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_per_model_id_counts = df['model_id'].value_counts()\n",
    "df_per_model_id_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chapter_title</th>\n",
       "      <th>file_name</th>\n",
       "      <th>chapter_id</th>\n",
       "      <th>model_id</th>\n",
       "      <th>latency_seconds</th>\n",
       "      <th>completion_token_count</th>\n",
       "      <th>prompt_token_count</th>\n",
       "      <th>input_token_price</th>\n",
       "      <th>output_token_pricing</th>\n",
       "      <th>chapter_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chapter: Higgs Boson, Dark Matter, and Quantum...</td>\n",
       "      <td>particle_physics_meeting.vtt</td>\n",
       "      <td>1</td>\n",
       "      <td>amazon.titan-text-express-v1</td>\n",
       "      <td>1.647802</td>\n",
       "      <td>13</td>\n",
       "      <td>537</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>\"Have you all seen the latest results from the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Unveiling the Mysteries of the Universe</td>\n",
       "      <td>particle_physics_meeting.vtt</td>\n",
       "      <td>2</td>\n",
       "      <td>amazon.titan-text-express-v1</td>\n",
       "      <td>1.554324</td>\n",
       "      <td>9</td>\n",
       "      <td>591</td>\n",
       "      <td>0.000473</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>\"Not necessarily. With the advent of more powe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Balancing Open Mind and Scientific Rigor</td>\n",
       "      <td>particle_physics_meeting.vtt</td>\n",
       "      <td>3</td>\n",
       "      <td>amazon.titan-text-express-v1</td>\n",
       "      <td>1.379880</td>\n",
       "      <td>8</td>\n",
       "      <td>629</td>\n",
       "      <td>0.000503</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>\"You make a valid point, David. As scientists,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Agreement and Enlightenment</td>\n",
       "      <td>particle_physics_meeting.vtt</td>\n",
       "      <td>4</td>\n",
       "      <td>amazon.titan-text-express-v1</td>\n",
       "      <td>1.162624</td>\n",
       "      <td>4</td>\n",
       "      <td>164</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>\"*nods in agreement* To the pursuit of underst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;title&gt;Exploring the Frontiers of Particle Phy...</td>\n",
       "      <td>particle_physics_meeting.vtt</td>\n",
       "      <td>1</td>\n",
       "      <td>anthropic.claude-3-haiku-20240307-v1:0</td>\n",
       "      <td>1.271018</td>\n",
       "      <td>24</td>\n",
       "      <td>625</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>\"Have you all seen the latest results from the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       chapter_title  \\\n",
       "0  Chapter: Higgs Boson, Dark Matter, and Quantum...   \n",
       "1            Unveiling the Mysteries of the Universe   \n",
       "2           Balancing Open Mind and Scientific Rigor   \n",
       "3                        Agreement and Enlightenment   \n",
       "4  <title>Exploring the Frontiers of Particle Phy...   \n",
       "\n",
       "                      file_name  chapter_id  \\\n",
       "0  particle_physics_meeting.vtt           1   \n",
       "1  particle_physics_meeting.vtt           2   \n",
       "2  particle_physics_meeting.vtt           3   \n",
       "3  particle_physics_meeting.vtt           4   \n",
       "4  particle_physics_meeting.vtt           1   \n",
       "\n",
       "                                 model_id  latency_seconds  \\\n",
       "0            amazon.titan-text-express-v1         1.647802   \n",
       "1            amazon.titan-text-express-v1         1.554324   \n",
       "2            amazon.titan-text-express-v1         1.379880   \n",
       "3            amazon.titan-text-express-v1         1.162624   \n",
       "4  anthropic.claude-3-haiku-20240307-v1:0         1.271018   \n",
       "\n",
       "   completion_token_count  prompt_token_count  input_token_price  \\\n",
       "0                      13                 537           0.000430   \n",
       "1                       9                 591           0.000473   \n",
       "2                       8                 629           0.000503   \n",
       "3                       4                 164           0.000131   \n",
       "4                      24                 625           0.000156   \n",
       "\n",
       "   output_token_pricing                                       chapter_text  \n",
       "0              0.000021  \"Have you all seen the latest results from the...  \n",
       "1              0.000014  \"Not necessarily. With the advent of more powe...  \n",
       "2              0.000013  \"You make a valid point, David. As scientists,...  \n",
       "3              0.000006  \"*nods in agreement* To the pursuit of underst...  \n",
       "4              0.000030  \"Have you all seen the latest results from the...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_dir = config['dir']['metrics']\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(metrics_dir, exist_ok=True)\n",
    "# Construct the file path\n",
    "metrics_file_path = os.path.join(metrics_dir, config['dir']['metrics_file'])\n",
    "df.to_csv(metrics_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latency_seconds</th>\n",
       "      <th>completion_token_count</th>\n",
       "      <th>prompt_token_count</th>\n",
       "      <th>input_token_price</th>\n",
       "      <th>output_token_pricing</th>\n",
       "      <th>p95_latency_seconds</th>\n",
       "      <th>avg_cost_per_txn</th>\n",
       "      <th>p95_cost_per_txn</th>\n",
       "      <th>p95_completion_token_count</th>\n",
       "      <th>p95_prompt_token_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>amazon.titan-text-express-v1</th>\n",
       "      <td>1.436158</td>\n",
       "      <td>8</td>\n",
       "      <td>480</td>\n",
       "      <td>0.000384</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>1.633780</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.000518</td>\n",
       "      <td>12.40</td>\n",
       "      <td>623.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anthropic.claude-3-haiku-20240307-v1:0</th>\n",
       "      <td>1.183008</td>\n",
       "      <td>22</td>\n",
       "      <td>555</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>1.294257</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>25.70</td>\n",
       "      <td>711.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anthropic.claude-3-sonnet-20240229-v1:0</th>\n",
       "      <td>2.322253</td>\n",
       "      <td>21</td>\n",
       "      <td>555</td>\n",
       "      <td>0.001665</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>2.593687</td>\n",
       "      <td>0.001980</td>\n",
       "      <td>0.002509</td>\n",
       "      <td>24.85</td>\n",
       "      <td>711.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta.llama2-13b-chat-v1</th>\n",
       "      <td>1.323700</td>\n",
       "      <td>13</td>\n",
       "      <td>488</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>1.612643</td>\n",
       "      <td>0.000380</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>19.80</td>\n",
       "      <td>631.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mistral.mistral-7b-instruct-v0:2</th>\n",
       "      <td>1.044126</td>\n",
       "      <td>24</td>\n",
       "      <td>496</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>1.403058</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>45.35</td>\n",
       "      <td>639.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         latency_seconds  \\\n",
       "model_id                                                   \n",
       "amazon.titan-text-express-v1                    1.436158   \n",
       "anthropic.claude-3-haiku-20240307-v1:0          1.183008   \n",
       "anthropic.claude-3-sonnet-20240229-v1:0         2.322253   \n",
       "meta.llama2-13b-chat-v1                         1.323700   \n",
       "mistral.mistral-7b-instruct-v0:2                1.044126   \n",
       "\n",
       "                                         completion_token_count  \\\n",
       "model_id                                                          \n",
       "amazon.titan-text-express-v1                                  8   \n",
       "anthropic.claude-3-haiku-20240307-v1:0                       22   \n",
       "anthropic.claude-3-sonnet-20240229-v1:0                      21   \n",
       "meta.llama2-13b-chat-v1                                      13   \n",
       "mistral.mistral-7b-instruct-v0:2                             24   \n",
       "\n",
       "                                         prompt_token_count  \\\n",
       "model_id                                                      \n",
       "amazon.titan-text-express-v1                            480   \n",
       "anthropic.claude-3-haiku-20240307-v1:0                  555   \n",
       "anthropic.claude-3-sonnet-20240229-v1:0                 555   \n",
       "meta.llama2-13b-chat-v1                                 488   \n",
       "mistral.mistral-7b-instruct-v0:2                        496   \n",
       "\n",
       "                                         input_token_price  \\\n",
       "model_id                                                     \n",
       "amazon.titan-text-express-v1                      0.000384   \n",
       "anthropic.claude-3-haiku-20240307-v1:0            0.000139   \n",
       "anthropic.claude-3-sonnet-20240229-v1:0           0.001665   \n",
       "meta.llama2-13b-chat-v1                           0.000366   \n",
       "mistral.mistral-7b-instruct-v0:2                  0.000074   \n",
       "\n",
       "                                         output_token_pricing  \\\n",
       "model_id                                                        \n",
       "amazon.titan-text-express-v1                         0.000014   \n",
       "anthropic.claude-3-haiku-20240307-v1:0               0.000028   \n",
       "anthropic.claude-3-sonnet-20240229-v1:0              0.000315   \n",
       "meta.llama2-13b-chat-v1                              0.000014   \n",
       "mistral.mistral-7b-instruct-v0:2                     0.000005   \n",
       "\n",
       "                                         p95_latency_seconds  \\\n",
       "model_id                                                       \n",
       "amazon.titan-text-express-v1                        1.633780   \n",
       "anthropic.claude-3-haiku-20240307-v1:0              1.294257   \n",
       "anthropic.claude-3-sonnet-20240229-v1:0             2.593687   \n",
       "meta.llama2-13b-chat-v1                             1.612643   \n",
       "mistral.mistral-7b-instruct-v0:2                    1.403058   \n",
       "\n",
       "                                         avg_cost_per_txn  p95_cost_per_txn  \\\n",
       "model_id                                                                      \n",
       "amazon.titan-text-express-v1                     0.000398          0.000518   \n",
       "anthropic.claude-3-haiku-20240307-v1:0           0.000166          0.000210   \n",
       "anthropic.claude-3-sonnet-20240229-v1:0          0.001980          0.002509   \n",
       "meta.llama2-13b-chat-v1                          0.000380          0.000493   \n",
       "mistral.mistral-7b-instruct-v0:2                 0.000079          0.000105   \n",
       "\n",
       "                                         p95_completion_token_count  \\\n",
       "model_id                                                              \n",
       "amazon.titan-text-express-v1                                  12.40   \n",
       "anthropic.claude-3-haiku-20240307-v1:0                        25.70   \n",
       "anthropic.claude-3-sonnet-20240229-v1:0                       24.85   \n",
       "meta.llama2-13b-chat-v1                                       19.80   \n",
       "mistral.mistral-7b-instruct-v0:2                              45.35   \n",
       "\n",
       "                                         p95_prompt_token_count  \n",
       "model_id                                                         \n",
       "amazon.titan-text-express-v1                             623.30  \n",
       "anthropic.claude-3-haiku-20240307-v1:0                   711.95  \n",
       "anthropic.claude-3-sonnet-20240229-v1:0                  711.95  \n",
       "meta.llama2-13b-chat-v1                                  631.30  \n",
       "mistral.mistral-7b-instruct-v0:2                         639.30  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary = df.groupby('model_id').mean(numeric_only=True)\n",
    "df_summary['p95_latency_seconds'] = df.groupby('model_id')['latency_seconds'].quantile(0.95)\n",
    "df_summary['avg_cost_per_txn'] = df_summary.input_token_price + df_summary.output_token_pricing\n",
    "df_summary['p95_cost_per_txn'] = df.groupby('model_id')['input_token_price'].quantile(0.95) + \\\n",
    "                                 df.groupby('model_id')['output_token_pricing'].quantile(0.95)\n",
    "df_summary.completion_token_count = df_summary.completion_token_count.astype(int)\n",
    "df_summary.prompt_token_count = df_summary.prompt_token_count.astype(int)\n",
    "df_summary['p95_completion_token_count'] = df.groupby('model_id')['completion_token_count'].quantile(0.95)\n",
    "df_summary['p95_prompt_token_count'] = df.groupby('model_id')['prompt_token_count'].quantile(0.95)\n",
    "df_summary = df_summary.drop(columns=['chapter_id'])\n",
    "df_summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate the long short view of the completions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>chapter_id</th>\n",
       "      <th>chapter_text</th>\n",
       "      <th>amazon.titan-text-express-v1_title</th>\n",
       "      <th>anthropic.claude-3-haiku-20240307-v1:0_title</th>\n",
       "      <th>anthropic.claude-3-sonnet-20240229-v1:0_title</th>\n",
       "      <th>meta.llama2-13b-chat-v1_title</th>\n",
       "      <th>mistral.mistral-7b-instruct-v0:2_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>particle_physics_meeting.vtt</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Have you all seen the latest results from the...</td>\n",
       "      <td>Higgs Boson, Dark Matter, and Quantum Gravity</td>\n",
       "      <td>Exploring the Frontiers of Particle Physics an...</td>\n",
       "      <td>Frontiers of Particle Physics Exploration</td>\n",
       "      <td>\"Unlocking the Secrets of the Higgs Boson\"</td>\n",
       "      <td>Exploring the Higgs Boson: Applications, Dark ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>particle_physics_meeting.vtt</td>\n",
       "      <td>2</td>\n",
       "      <td>\"Not necessarily. With the advent of more powe...</td>\n",
       "      <td>Unveiling the Mysteries of the Universe</td>\n",
       "      <td>Exploring the Frontiers of Physics and Cosmology</td>\n",
       "      <td>Frontiers of Physics: Antimatter and Cosmic En...</td>\n",
       "      <td>\"Unlocking the Secrets of the Universe: The Po...</td>\n",
       "      <td>Exploring Reality's Depths: Particle Accelerat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>particle_physics_meeting.vtt</td>\n",
       "      <td>3</td>\n",
       "      <td>\"You make a valid point, David. As scientists,...</td>\n",
       "      <td>Balancing Open Mind and Scientific Rigor</td>\n",
       "      <td>Balancing Open-Mindedness and Rigorous Standar...</td>\n",
       "      <td>Balancing Open-Mindedness and Rigor in Scienti...</td>\n",
       "      <td>\"Scientific Inquiry and the Pursuit of Truth\"</td>\n",
       "      <td>Balancing Open-Mindedness and Scientific Stand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>particle_physics_meeting.vtt</td>\n",
       "      <td>4</td>\n",
       "      <td>\"*nods in agreement* To the pursuit of underst...</td>\n",
       "      <td>Agreement and Enlightenment</td>\n",
       "      <td>Commitment to Enlightening Discourse</td>\n",
       "      <td>Enlightening Discussions, Open Exchange</td>\n",
       "      <td>\"Pursuing Understanding and Open Ideas\"</td>\n",
       "      <td>Pursuit of Understanding: Open Idea Exchange</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      file_name  chapter_id  \\\n",
       "0  particle_physics_meeting.vtt           1   \n",
       "1  particle_physics_meeting.vtt           2   \n",
       "2  particle_physics_meeting.vtt           3   \n",
       "3  particle_physics_meeting.vtt           4   \n",
       "\n",
       "                                        chapter_text  \\\n",
       "0  \"Have you all seen the latest results from the...   \n",
       "1  \"Not necessarily. With the advent of more powe...   \n",
       "2  \"You make a valid point, David. As scientists,...   \n",
       "3  \"*nods in agreement* To the pursuit of underst...   \n",
       "\n",
       "              amazon.titan-text-express-v1_title  \\\n",
       "0  Higgs Boson, Dark Matter, and Quantum Gravity   \n",
       "1        Unveiling the Mysteries of the Universe   \n",
       "2       Balancing Open Mind and Scientific Rigor   \n",
       "3                    Agreement and Enlightenment   \n",
       "\n",
       "        anthropic.claude-3-haiku-20240307-v1:0_title  \\\n",
       "0  Exploring the Frontiers of Particle Physics an...   \n",
       "1   Exploring the Frontiers of Physics and Cosmology   \n",
       "2  Balancing Open-Mindedness and Rigorous Standar...   \n",
       "3               Commitment to Enlightening Discourse   \n",
       "\n",
       "       anthropic.claude-3-sonnet-20240229-v1:0_title  \\\n",
       "0          Frontiers of Particle Physics Exploration   \n",
       "1  Frontiers of Physics: Antimatter and Cosmic En...   \n",
       "2  Balancing Open-Mindedness and Rigor in Scienti...   \n",
       "3            Enlightening Discussions, Open Exchange   \n",
       "\n",
       "                       meta.llama2-13b-chat-v1_title  \\\n",
       "0         \"Unlocking the Secrets of the Higgs Boson\"   \n",
       "1  \"Unlocking the Secrets of the Universe: The Po...   \n",
       "2      \"Scientific Inquiry and the Pursuit of Truth\"   \n",
       "3            \"Pursuing Understanding and Open Ideas\"   \n",
       "\n",
       "              mistral.mistral-7b-instruct-v0:2_title  \n",
       "0  Exploring the Higgs Boson: Applications, Dark ...  \n",
       "1  Exploring Reality's Depths: Particle Accelerat...  \n",
       "2  Balancing Open-Mindedness and Scientific Stand...  \n",
       "3       Pursuit of Understanding: Open Idea Exchange  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_cols = ['file_name', 'chapter_id', 'chapter_text']\n",
    "def sanitize_title(title):\n",
    "    if title is None:\n",
    "        return title\n",
    "    title = title.replace(\"<title>\", \"\").replace(\"</title>\", \"\")\n",
    "    title = title.replace(\"Title:\", \"\")\n",
    "    title = title.replace(\"Chapter: \", \"\")\n",
    "    title = title.replace(\"Chapter \", \"\")\n",
    "    \n",
    "    title = title.strip()\n",
    "    title = title.split(\"\\n\")[0]\n",
    "    return title\n",
    "df.chapter_title = df.chapter_title.map(sanitize_title)\n",
    "df_pivoted = df.pivot_table(index=index_cols, columns='model_id', values='chapter_title', aggfunc='first')\n",
    "cols_other_than_index_cols = [f\"{c}_title\" for c in df_pivoted.columns if c not in index_cols]\n",
    "df_pivoted = df_pivoted.reset_index()\n",
    "df_pivoted.columns = index_cols + cols_other_than_index_cols\n",
    "df_pivoted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the file path\n",
    "movel_evals_fpath = os.path.join(metrics_dir, config['dir']['model_evals_file'])\n",
    "df_pivoted.to_csv(movel_evals_fpath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_summary(row, summary):\n",
    "    return summary.format(model_id=row.name,\n",
    "                          avg_latency=round(row['latency_seconds'], 4),\n",
    "                          p95_latency=round(row['p95_latency_seconds'], 4),\n",
    "                          avg_cost=round(10000*row['avg_cost_per_txn'], 6),\n",
    "                          p95_cost_per_txn=round(10000*row['p95_cost_per_txn'], 6),\n",
    "                          avg_prompt_token_count=row['prompt_token_count'].astype(int),\n",
    "                          p95_prompt_token_count=row['p95_prompt_token_count'].astype(int),\n",
    "                          avg_completion_token_count=row['completion_token_count'].astype(int),\n",
    "                          p95_completion_token_count=row['p95_completion_token_count'].astype(int),\n",
    "                          count=int(row['count']))\n",
    "df_summary = pd.merge(left=df_summary, right=df_per_model_id_counts, on=\"model_id\", how=\"left\")\n",
    "\n",
    "df_summary['overall_report'] = df_summary.apply(lambda r: create_summary(r, config['report']['summary_text']), axis=1)\n",
    "df_summary = df_summary.round(6)\n",
    "\n",
    "summary_metrics_file_path = os.path.join(metrics_dir, config['dir']['summary_metrics_file'])\n",
    "df_summary.to_csv(summary_metrics_file_path, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latency_seconds</th>\n",
       "      <th>completion_token_count</th>\n",
       "      <th>prompt_token_count</th>\n",
       "      <th>input_token_price</th>\n",
       "      <th>output_token_pricing</th>\n",
       "      <th>p95_latency_seconds</th>\n",
       "      <th>avg_cost_per_txn</th>\n",
       "      <th>p95_cost_per_txn</th>\n",
       "      <th>p95_completion_token_count</th>\n",
       "      <th>p95_prompt_token_count</th>\n",
       "      <th>count</th>\n",
       "      <th>overall_report</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>amazon.titan-text-express-v1</th>\n",
       "      <td>1.436158</td>\n",
       "      <td>8</td>\n",
       "      <td>480</td>\n",
       "      <td>0.000384</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>1.633780</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.000518</td>\n",
       "      <td>12.40</td>\n",
       "      <td>623.30</td>\n",
       "      <td>4</td>\n",
       "      <td>The average inference latency for this workloa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anthropic.claude-3-haiku-20240307-v1:0</th>\n",
       "      <td>1.183008</td>\n",
       "      <td>22</td>\n",
       "      <td>555</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>1.294257</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>25.70</td>\n",
       "      <td>711.95</td>\n",
       "      <td>4</td>\n",
       "      <td>The average inference latency for this workloa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anthropic.claude-3-sonnet-20240229-v1:0</th>\n",
       "      <td>2.322253</td>\n",
       "      <td>21</td>\n",
       "      <td>555</td>\n",
       "      <td>0.001665</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>2.593687</td>\n",
       "      <td>0.001980</td>\n",
       "      <td>0.002509</td>\n",
       "      <td>24.85</td>\n",
       "      <td>711.95</td>\n",
       "      <td>4</td>\n",
       "      <td>The average inference latency for this workloa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta.llama2-13b-chat-v1</th>\n",
       "      <td>1.323700</td>\n",
       "      <td>13</td>\n",
       "      <td>488</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>1.612643</td>\n",
       "      <td>0.000380</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>19.80</td>\n",
       "      <td>631.30</td>\n",
       "      <td>4</td>\n",
       "      <td>The average inference latency for this workloa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mistral.mistral-7b-instruct-v0:2</th>\n",
       "      <td>1.044126</td>\n",
       "      <td>24</td>\n",
       "      <td>496</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>1.403058</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>45.35</td>\n",
       "      <td>639.30</td>\n",
       "      <td>4</td>\n",
       "      <td>The average inference latency for this workloa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         latency_seconds  \\\n",
       "model_id                                                   \n",
       "amazon.titan-text-express-v1                    1.436158   \n",
       "anthropic.claude-3-haiku-20240307-v1:0          1.183008   \n",
       "anthropic.claude-3-sonnet-20240229-v1:0         2.322253   \n",
       "meta.llama2-13b-chat-v1                         1.323700   \n",
       "mistral.mistral-7b-instruct-v0:2                1.044126   \n",
       "\n",
       "                                         completion_token_count  \\\n",
       "model_id                                                          \n",
       "amazon.titan-text-express-v1                                  8   \n",
       "anthropic.claude-3-haiku-20240307-v1:0                       22   \n",
       "anthropic.claude-3-sonnet-20240229-v1:0                      21   \n",
       "meta.llama2-13b-chat-v1                                      13   \n",
       "mistral.mistral-7b-instruct-v0:2                             24   \n",
       "\n",
       "                                         prompt_token_count  \\\n",
       "model_id                                                      \n",
       "amazon.titan-text-express-v1                            480   \n",
       "anthropic.claude-3-haiku-20240307-v1:0                  555   \n",
       "anthropic.claude-3-sonnet-20240229-v1:0                 555   \n",
       "meta.llama2-13b-chat-v1                                 488   \n",
       "mistral.mistral-7b-instruct-v0:2                        496   \n",
       "\n",
       "                                         input_token_price  \\\n",
       "model_id                                                     \n",
       "amazon.titan-text-express-v1                      0.000384   \n",
       "anthropic.claude-3-haiku-20240307-v1:0            0.000139   \n",
       "anthropic.claude-3-sonnet-20240229-v1:0           0.001665   \n",
       "meta.llama2-13b-chat-v1                           0.000366   \n",
       "mistral.mistral-7b-instruct-v0:2                  0.000074   \n",
       "\n",
       "                                         output_token_pricing  \\\n",
       "model_id                                                        \n",
       "amazon.titan-text-express-v1                         0.000014   \n",
       "anthropic.claude-3-haiku-20240307-v1:0               0.000028   \n",
       "anthropic.claude-3-sonnet-20240229-v1:0              0.000315   \n",
       "meta.llama2-13b-chat-v1                              0.000014   \n",
       "mistral.mistral-7b-instruct-v0:2                     0.000005   \n",
       "\n",
       "                                         p95_latency_seconds  \\\n",
       "model_id                                                       \n",
       "amazon.titan-text-express-v1                        1.633780   \n",
       "anthropic.claude-3-haiku-20240307-v1:0              1.294257   \n",
       "anthropic.claude-3-sonnet-20240229-v1:0             2.593687   \n",
       "meta.llama2-13b-chat-v1                             1.612643   \n",
       "mistral.mistral-7b-instruct-v0:2                    1.403058   \n",
       "\n",
       "                                         avg_cost_per_txn  p95_cost_per_txn  \\\n",
       "model_id                                                                      \n",
       "amazon.titan-text-express-v1                     0.000398          0.000518   \n",
       "anthropic.claude-3-haiku-20240307-v1:0           0.000166          0.000210   \n",
       "anthropic.claude-3-sonnet-20240229-v1:0          0.001980          0.002509   \n",
       "meta.llama2-13b-chat-v1                          0.000380          0.000493   \n",
       "mistral.mistral-7b-instruct-v0:2                 0.000079          0.000105   \n",
       "\n",
       "                                         p95_completion_token_count  \\\n",
       "model_id                                                              \n",
       "amazon.titan-text-express-v1                                  12.40   \n",
       "anthropic.claude-3-haiku-20240307-v1:0                        25.70   \n",
       "anthropic.claude-3-sonnet-20240229-v1:0                       24.85   \n",
       "meta.llama2-13b-chat-v1                                       19.80   \n",
       "mistral.mistral-7b-instruct-v0:2                              45.35   \n",
       "\n",
       "                                         p95_prompt_token_count  count  \\\n",
       "model_id                                                                 \n",
       "amazon.titan-text-express-v1                             623.30      4   \n",
       "anthropic.claude-3-haiku-20240307-v1:0                   711.95      4   \n",
       "anthropic.claude-3-sonnet-20240229-v1:0                  711.95      4   \n",
       "meta.llama2-13b-chat-v1                                  631.30      4   \n",
       "mistral.mistral-7b-instruct-v0:2                         639.30      4   \n",
       "\n",
       "                                                                            overall_report  \n",
       "model_id                                                                                    \n",
       "amazon.titan-text-express-v1             The average inference latency for this workloa...  \n",
       "anthropic.claude-3-haiku-20240307-v1:0   The average inference latency for this workloa...  \n",
       "anthropic.claude-3-sonnet-20240229-v1:0  The average inference latency for this workloa...  \n",
       "meta.llama2-13b-chat-v1                  The average inference latency for this workloa...  \n",
       "mistral.mistral-7b-instruct-v0:2         The average inference latency for this workloa...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the df_summary elements\n",
    "df_summary.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
